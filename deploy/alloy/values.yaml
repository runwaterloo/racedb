alloy:
  configMap:
    create: true
    content: |

      ///////////////////////////////////////////////////////////////////////////////////
      // Prometheus writer
      prometheus.remote_write "grafanacloud" {
        endpoint {
          url = "https://prometheus-prod-32-prod-ca-east-0.grafana.net/api/prom/push"

          basic_auth {
            username = sys.env("PROM_USERNAME")
            password = sys.env("GRAFANA_API_TOKEN")
          }
        }
      }
      ///////////////////////////////////////////////////////////////////////////////////

      ///////////////////////////////////////////////////////////////////////////////////
      // Loki writer
      loki.write "grafanacloud" {
        endpoint {
          url = "https://logs-prod-018.grafana.net/loki/api/v1/push"

          basic_auth {
            username = sys.env("LOKI_USERNAME")
            password = sys.env("GRAFANA_API_TOKEN")
          }
        }
      }
      ///////////////////////////////////////////////////////////////////////////////////

      ///////////////////////////////////////////////////////////////////////////////////
      // Node exporter scraper
      prometheus.scrape "unix" {
        targets = prometheus.exporter.unix.localhost.targets
        forward_to = [prometheus.relabel.set_labels.receiver]
      }
      ///////////////////////////////////////////////////////////////////////////////////

      ///////////////////////////////////////////////////////////////////////////////////
      // Process scraper
      prometheus.scrape "processes" {
        targets    = prometheus.exporter.process.processes.targets
        forward_to = [prometheus.remote_write.grafanacloud.receiver]
      }
      ///////////////////////////////////////////////////////////////////////////////////

      ///////////////////////////////////////////////////////////////////////////////////
      // Traefik scraper
      prometheus.scrape "traefik" {
        targets = [
          {"__address__" = "traefik:9100", "instance" = "traefik"},
        ]
        forward_to = [prometheus.remote_write.grafanacloud.receiver]
      }
      ///////////////////////////////////////////////////////////////////////////////////

      ///////////////////////////////////////////////////////////////////////////////////
      // MySQL scraper
      prometheus.scrape "mysql" {
        targets    = prometheus.exporter.mysql.rds.targets
        forward_to = [prometheus.remote_write.grafanacloud.receiver]
      }
      ///////////////////////////////////////////////////////////////////////////////////

      prometheus.exporter.unix "localhost" {
        procfs_path = "/host/proc"
        sysfs_path  = "/host/sys"
        rootfs_path = "/rootfs"
        include_exporter_metrics = true
      }

      prometheus.relabel "set_labels" {
        forward_to = [prometheus.remote_write.grafanacloud.receiver]
        rule {
          action = "replace"
          target_label = "nodename"
          replacement = "rrw"
        }
      }

      prometheus.exporter.process "processes" {
        procfs_path = "/host/proc"
        matcher {
          comm = ["alloy", "celery", "containerd", "containerd-shim", "coredns", "gunicorn", "k3s-server", "metrics-server", "node_exporter", "prometheus-conf", "python", "redis-server", "traefik"]
        }
       }

      prometheus.exporter.mysql "rds" {
        data_source_name = sys.env("MYSQL_DATA_SOURCE_NAME")
      }


      // discovery.kubernetes allows you to find scrape targets from Kubernetes resources.
      // It watches cluster state and ensures targets are continually synced with what is currently running in your cluster.
      discovery.kubernetes "pod" {
        role = "pod"
      }

      // discovery.relabel rewrites the label set of the input targets by applying one or more relabeling rules.
      // If no rules are defined, then the input targets are exported as-is.
      discovery.relabel "pod_logs" {
        targets = discovery.kubernetes.pod.targets

        // Label creation - "namespace" field from "__meta_kubernetes_namespace"
        rule {
          source_labels = ["__meta_kubernetes_namespace"]
          action = "replace"
          target_label = "namespace"
        }

        // Label creation - "pod" field from "__meta_kubernetes_pod_name"
        rule {
          source_labels = ["__meta_kubernetes_pod_name"]
          action = "replace"
          target_label = "pod"
        }

        // Label creation - "container" field from "__meta_kubernetes_pod_container_name"
        rule {
          source_labels = ["__meta_kubernetes_pod_container_name"]
          action = "replace"
          target_label = "container"
        }

        // Label creation -  "app" field from "__meta_kubernetes_pod_label_app_kubernetes_io_name"
        rule {
          source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
          action = "replace"
          target_label = "app"
        }

        // Label creation -  "service_name" field from "__meta_kubernetes_pod_label_app_kubernetes_io_instance"
        rule {
          source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_instance"]
          action = "replace"
          target_label = "service_name"
        }

        // Label creation -  "job" field from "__meta_kubernetes_namespace" and "__meta_kubernetes_pod_container_name"
        // Concatenate values __meta_kubernetes_namespace/__meta_kubernetes_pod_container_name
        rule {
          source_labels = ["__meta_kubernetes_namespace", "__meta_kubernetes_pod_container_name"]
          action = "replace"
          target_label = "job"
          separator = "/"
          replacement = "$1"
        }

        // Label creation - "container" field from "__meta_kubernetes_pod_uid" and "__meta_kubernetes_pod_container_name"
        // Concatenate values __meta_kubernetes_pod_uid/__meta_kubernetes_pod_container_name.log
        rule {
          source_labels = ["__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
          action = "replace"
          target_label = "__path__"
          separator = "/"
          replacement = "/var/log/pods/*$1/*.log"
        }

        // Label creation -  "container_runtime" field from "__meta_kubernetes_pod_container_id"
        rule {
          source_labels = ["__meta_kubernetes_pod_container_id"]
          action = "replace"
          target_label = "container_runtime"
          regex = "^(\\S+):\\/\\/.+$"
          replacement = "$1"
        }
      }

      // loki.source.kubernetes tails logs from Kubernetes containers using the Kubernetes API.
      loki.source.kubernetes "pod_logs" {
        targets    = discovery.relabel.pod_logs.output
        forward_to = [loki.process.pod_logs.receiver]
      }

      // loki.process receives log entries from other Loki components, applies one or more processing stages,
      // and forwards the results to the list of receivers in the component's arguments.
      loki.process "pod_logs" {
        stage.static_labels {
            values = {
              cluster = "default",
            }
        }

        forward_to = [loki.write.grafanacloud.receiver]
      }

      ///////////////////////////////////////////////////////////////////////////////////
      // Discover and scrape django metrics from rrw web pods
      discovery.relabel "rrw_web_pods" {
      targets = discovery.kubernetes.pod.targets
        // Keep only pods with correct labels
        rule {
          action        = "keep"
          source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_instance", "__meta_kubernetes_pod_label_app_kubernetes_io_task"]
          regex         = "racedb;web"
        }
        // Set instance label to pod IP
        rule {
          action        = "replace"
          source_labels = ["__meta_kubernetes_pod_ip"]
          target_label  = "__address__"
          replacement   = "$1:8000"
        }
      }
      prometheus.scrape "racedb_web" {
        targets    = discovery.relabel.rrw_web_pods.output
        forward_to = [prometheus.remote_write.grafanacloud.receiver]
        job_name = "django-prometheus"
      }
      ////////////////////////////////////////////////////////////////////////////////////

      ///////////////////////////////////////////////////////////////////////////////////
      // Send the underlying host journal logs to Loki
      loki.source.journal "host_journal" {
        path        = "/host/journal"
        format_as_json = true
        labels = {
          job      = "systemd-journal",
        }
        forward_to = [loki.write.grafanacloud.receiver]
      }
      ///////////////////////////////////////////////////////////////////////////////////

  envFrom:
    - secretRef:
        name: alloy-secrets
  mounts:
    extra:
      - name: proc
        mountPath: /host/proc
        readOnly: true
      - name: sys
        mountPath: /host/sys
        readOnly: true
      - name: root
        mountPath: /rootfs
        readOnly: true
      - name: journal
        mountPath: /host/journal
        readOnly: true

controller:
  volumes:
    extra:
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys
      - name: root
        hostPath:
          path: /
      - name: journal
        hostPath:
          path: /var/log/journal
